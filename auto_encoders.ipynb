{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from timeit import default_timer as timer\n",
    "from datetime import timedelta\n",
    "import os\n",
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "from read_scripts import dict_2_arr \n",
    "from read_scripts import read_dataset \n",
    "from sklearn.utils.extmath import randomized_svd\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "task = \"remote_homology\"\n",
    "\n",
    "def fit_logistic(X, y):\n",
    "    start = timer()\n",
    "    clf = LogisticRegression(max_iter=5000)\n",
    "    clf.fit(X, y)\n",
    "    end = timer()\n",
    "    print(f\"fit time: \", timedelta(seconds=end-start))\n",
    "    \n",
    "    train_score = clf.score(X, y)\n",
    "    print(f\"model train score: \", train_score)\n",
    "    \n",
    "    # when run will play a ping sound!\n",
    "    os.system(\"printf '\\a'\")\n",
    "    os.system(\"printf '\\a'\")\n",
    "    os.system(\"printf '\\a'\")\n",
    "    print(\"Done!\")\n",
    "    \n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_single_model_normalized_corpus(model):\n",
    "    ys = []\n",
    "    Xs = []\n",
    "\n",
    "    # read all splits\n",
    "    for split in ['train', 'valid', 'test_fold_holdout', 'test_superfamily_holdout', 'test_family_holdout']:\n",
    "\n",
    "        y_dict = read_dataset('label', task, split)\n",
    "        X, y = dict_2_arr(read_dataset(model, task, split), y_dict)\n",
    "        \n",
    "        ys.append(y)\n",
    "        Xs.append(X)  \n",
    "    \n",
    "    # concat all splits\n",
    "    corpus = np.concatenate(Xs, axis=0)\n",
    "    \n",
    "    return corpus, ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_combined_normalized_corpus_weighted(weights):\n",
    "    ys = []\n",
    "    els = []\n",
    "    trfs = []\n",
    "    unis = []\n",
    "\n",
    "    # read all splits\n",
    "    for split in ['train', 'valid', 'test_fold_holdout', 'test_superfamily_holdout', 'test_family_holdout']:\n",
    "\n",
    "        y_dict = read_dataset('label', task, split)\n",
    "        X_e, y = dict_2_arr(read_dataset('elmo', task, split), y_dict)\n",
    "        X_t, y = dict_2_arr(read_dataset('transformer', task, split), y_dict)\n",
    "        X_u, y = dict_2_arr(read_dataset('unirep', task, split), y_dict)\n",
    "\n",
    "        ys.append(y)\n",
    "        els.append(X_e)  \n",
    "        trfs.append(X_t)\n",
    "        unis.append(X_u)\n",
    "    \n",
    "    # concat all splits\n",
    "    e_corpus = np.concatenate(els, axis=0)\n",
    "    t_corpus = np.concatenate(trfs, axis=0)\n",
    "    u_corpus = np.concatenate(unis, axis=0)\n",
    "    \n",
    "    # normalize each indvidually \n",
    "    e_corpus = preprocessing.normalize(e_corpus, norm='l2') * weights[0]\n",
    "    t_corpus = preprocessing.normalize(t_corpus, norm='l2') * weights[1]\n",
    "    u_corpus = preprocessing.normalize(u_corpus, norm='l2') * weights[2]\n",
    "    \n",
    "    # concatenate all corpuses\n",
    "    combined = np.concatenate([e_corpus, t_corpus, u_corpus], axis=1)\n",
    "    \n",
    "    return combined, ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_over_corpus(corpus, ys, model_name):\n",
    "\n",
    "    all_score = {}\n",
    "\n",
    "    # get out training slice\n",
    "    X_train = corpus[:len(ys[0])]\n",
    "    y_train = ys[0]\n",
    "\n",
    "    # scale\n",
    "    scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "    X_train = scaler.transform(X_train)\n",
    "\n",
    "    # fit!\n",
    "    clf = fit_logistic(X_train, y_train)\n",
    "\n",
    "    # record train score\n",
    "    train_score = clf.score(X_train, y_train)\n",
    "    print(f\"{model_name} train score: \", train_score)\n",
    "\n",
    "    all_score[\"train\"]  = train_score\n",
    "\n",
    "    # get slices for remaing splits and score\n",
    "    remain_splits = ['valid', 'test_fold_holdout', 'test_superfamily_holdout', 'test_family_holdout']\n",
    "    end = len(ys[0])\n",
    "    for i in range(len(remain_splits)):\n",
    "        split = remain_splits[i]\n",
    "        start = end\n",
    "        end = len(ys[i+1])+start\n",
    "\n",
    "        X = corpus[start:end]\n",
    "        y = ys[i+1]\n",
    "\n",
    "        X = scaler.transform(X)\n",
    "\n",
    "        test_score = clf.score(X, y)\n",
    "\n",
    "        all_score[split]  = test_score\n",
    "\n",
    "        print(f\"{model_name} {split} score: \", test_score)\n",
    "\n",
    "    return all_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_auto_encoder(X, latent_dim, hidden_layers):\n",
    "\n",
    "    n_input = X.shape[1]\n",
    "\n",
    "    full_layers = hidden_layers + [latent_dim] + hidden_layers[::-1]\n",
    "    print(\"layers\", full_layers)\n",
    "    \n",
    "    reg = MLPRegressor(hidden_layer_sizes = full_layers, \n",
    "                       activation = 'relu', \n",
    "                       solver = 'adam', \n",
    "                       learning_rate_init = 0.0001, \n",
    "                       max_iter = 100, \n",
    "                       tol = 0.0000001, \n",
    "                       verbose = False)\n",
    "    \n",
    "    print(\"fitting auto_encoder...\")\n",
    "    reg.fit(X, X)\n",
    "    \n",
    "    auto_encoder_train_score = reg.score(X, X)\n",
    "    print(\"auto_encoder_train_score: \", auto_encoder_train_score)\n",
    "    return reg\n",
    "\n",
    "\n",
    "def encoder(X, reg):\n",
    "    print(\"encoding...\")\n",
    "    X = np.asmatrix(X)\n",
    "    \n",
    "    encoder1 = X*reg.coefs_[0] + reg.intercepts_[0]\n",
    "    encoder1 = (np.exp(encoder1) - np.exp(-encoder1))/(np.exp(encoder1) + np.exp(-encoder1))\n",
    "    \n",
    "    encoder2 = encoder1*reg.coefs_[1] + reg.intercepts_[1]\n",
    "    encoder2 = (np.exp(encoder2) - np.exp(-encoder2))/(np.exp(encoder2) + np.exp(-encoder2))\n",
    "    \n",
    "    latent = encoder2*reg.coefs_[2] + reg.intercepts_[2]\n",
    "    latent = (np.exp(latent) - np.exp(-latent))/(np.exp(latent) + np.exp(-latent))\n",
    "    \n",
    "    print(\"encoded as: \", latent.shape)\n",
    "    \n",
    "    return np.asarray(latent)\n",
    "\n",
    "def train_and_encode(X, latent_dim=200, hidden_layers=[500, 300]):\n",
    "    \n",
    "    reg = train_auto_encoder(X, latent_dim, hidden_layers)\n",
    "    X_encoded = encoder(X, reg)\n",
    "    \n",
    "    return X_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_conact_then_auto_encode_for_dim(X, ys, dim):\n",
    "    \n",
    "    hidden_layers = [1200, int((d+1200)/2)]\n",
    "    X = train_and_encode(X, latent_dim=dim, hidden_layers=hidden_layers)\n",
    "    scores = train_test_over_corpus(X, ys, f\"concat_then_auto_encode dim {dim}\")\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, ys = get_combined_normalized_corpus_weighted([6,3,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layers [1200, 605, 10, 605, 1200]\n",
      "fitting auto_encoder...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/julesberman/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auto_encoder_train_score:  -0.18793691247078564\n",
      "encoding...\n",
      "encoded as:  (16281, 10)\n",
      "fit time:  0:02:03.444124\n",
      "model train score:  0.38228362454286874\n",
      "Done!\n",
      "concat_then_auto_encode dim 10 train score:  0.38228362454286874\n",
      "concat_then_auto_encode dim 10 valid score:  0.14032697547683923\n",
      "concat_then_auto_encode dim 10 test_fold_holdout score:  0.13370473537604458\n",
      "concat_then_auto_encode dim 10 test_superfamily_holdout score:  0.17252396166134185\n",
      "concat_then_auto_encode dim 10 test_family_holdout score:  0.5487421383647799\n",
      "layers [1200, 610, 20, 610, 1200]\n",
      "fitting auto_encoder...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/julesberman/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auto_encoder_train_score:  -0.2058248321870798\n",
      "encoding...\n",
      "encoded as:  (16281, 20)\n",
      "fit time:  0:02:19.995402\n",
      "model train score:  0.6007314099959367\n",
      "Done!\n",
      "concat_then_auto_encode dim 20 train score:  0.6007314099959367\n",
      "concat_then_auto_encode dim 20 valid score:  0.21934604904632152\n",
      "concat_then_auto_encode dim 20 test_fold_holdout score:  0.18802228412256267\n",
      "concat_then_auto_encode dim 20 test_superfamily_holdout score:  0.2715654952076677\n",
      "concat_then_auto_encode dim 20 test_family_holdout score:  0.7287735849056604\n",
      "layers [1200, 625, 50, 625, 1200]\n",
      "fitting auto_encoder...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/julesberman/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auto_encoder_train_score:  -0.13138658771454115\n",
      "encoding...\n",
      "encoded as:  (16281, 50)\n",
      "fit time:  0:03:27.928876\n",
      "model train score:  0.8867127184071516\n",
      "Done!\n",
      "concat_then_auto_encode dim 50 train score:  0.8867127184071516\n",
      "concat_then_auto_encode dim 50 valid score:  0.3201634877384196\n",
      "concat_then_auto_encode dim 50 test_fold_holdout score:  0.22284122562674094\n",
      "concat_then_auto_encode dim 50 test_superfamily_holdout score:  0.3738019169329074\n",
      "concat_then_auto_encode dim 50 test_family_holdout score:  0.8781446540880503\n",
      "layers [1200, 650, 100, 650, 1200]\n",
      "fitting auto_encoder...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/julesberman/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auto_encoder_train_score:  0.025393329085391984\n",
      "encoding...\n",
      "encoded as:  (16281, 100)\n",
      "fit time:  0:04:46.080643\n",
      "model train score:  0.9775700934579439\n",
      "Done!\n",
      "concat_then_auto_encode dim 100 train score:  0.9775700934579439\n",
      "concat_then_auto_encode dim 100 valid score:  0.35013623978201636\n",
      "concat_then_auto_encode dim 100 test_fold_holdout score:  0.25487465181058494\n",
      "concat_then_auto_encode dim 100 test_superfamily_holdout score:  0.4049520766773163\n",
      "concat_then_auto_encode dim 100 test_family_holdout score:  0.9095911949685535\n",
      "layers [1200, 675, 150, 675, 1200]\n",
      "fitting auto_encoder...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/julesberman/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auto_encoder_train_score:  0.037409317666398795\n",
      "encoding...\n",
      "encoded as:  (16281, 150)\n",
      "fit time:  0:05:20.359345\n",
      "model train score:  0.9947988622511175\n",
      "Done!\n",
      "concat_then_auto_encode dim 150 train score:  0.9947988622511175\n",
      "concat_then_auto_encode dim 150 valid score:  0.3542234332425068\n",
      "concat_then_auto_encode dim 150 test_fold_holdout score:  0.2381615598885794\n",
      "concat_then_auto_encode dim 150 test_superfamily_holdout score:  0.43690095846645366\n",
      "concat_then_auto_encode dim 150 test_family_holdout score:  0.9150943396226415\n",
      "layers [1200, 700, 200, 700, 1200]\n",
      "fitting auto_encoder...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/julesberman/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auto_encoder_train_score:  0.04354044167265998\n",
      "encoding...\n",
      "encoded as:  (16281, 200)\n",
      "fit time:  0:06:05.850699\n",
      "model train score:  0.9984559122308004\n",
      "Done!\n",
      "concat_then_auto_encode dim 200 train score:  0.9984559122308004\n",
      "concat_then_auto_encode dim 200 valid score:  0.3637602179836512\n",
      "concat_then_auto_encode dim 200 test_fold_holdout score:  0.24930362116991645\n",
      "concat_then_auto_encode dim 200 test_superfamily_holdout score:  0.4193290734824281\n",
      "concat_then_auto_encode dim 200 test_family_holdout score:  0.9182389937106918\n",
      "layers [1200, 725, 250, 725, 1200]\n",
      "fitting auto_encoder...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/julesberman/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auto_encoder_train_score:  0.0014086553638461474\n",
      "encoding...\n",
      "encoded as:  (16281, 250)\n",
      "fit time:  0:05:30.682865\n",
      "model train score:  0.9997561966680212\n",
      "Done!\n",
      "concat_then_auto_encode dim 250 train score:  0.9997561966680212\n",
      "concat_then_auto_encode dim 250 valid score:  0.3555858310626703\n",
      "concat_then_auto_encode dim 250 test_fold_holdout score:  0.2576601671309192\n",
      "concat_then_auto_encode dim 250 test_superfamily_holdout score:  0.41533546325878595\n",
      "concat_then_auto_encode dim 250 test_family_holdout score:  0.9190251572327044\n",
      "layers [1200, 750, 300, 750, 1200]\n",
      "fitting auto_encoder...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/julesberman/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auto_encoder_train_score:  0.09248075169947526\n",
      "encoding...\n",
      "encoded as:  (16281, 300)\n",
      "fit time:  0:06:48.813903\n",
      "model train score:  0.9999187322226737\n",
      "Done!\n",
      "concat_then_auto_encode dim 300 train score:  0.9999187322226737\n",
      "concat_then_auto_encode dim 300 valid score:  0.36648501362397823\n",
      "concat_then_auto_encode dim 300 test_fold_holdout score:  0.22562674094707522\n",
      "concat_then_auto_encode dim 300 test_superfamily_holdout score:  0.4273162939297125\n",
      "concat_then_auto_encode dim 300 test_family_holdout score:  0.9276729559748428\n",
      "layers [1200, 775, 350, 775, 1200]\n",
      "fitting auto_encoder...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/julesberman/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auto_encoder_train_score:  0.11037682796386543\n",
      "encoding...\n",
      "encoded as:  (16281, 350)\n",
      "fit time:  0:07:43.093960\n",
      "model train score:  0.9999187322226737\n",
      "Done!\n",
      "concat_then_auto_encode dim 350 train score:  0.9999187322226737\n",
      "concat_then_auto_encode dim 350 valid score:  0.3801089918256131\n",
      "concat_then_auto_encode dim 350 test_fold_holdout score:  0.2590529247910863\n",
      "concat_then_auto_encode dim 350 test_superfamily_holdout score:  0.43929712460063897\n",
      "concat_then_auto_encode dim 350 test_family_holdout score:  0.9237421383647799\n",
      "layers [1200, 800, 400, 800, 1200]\n",
      "fitting auto_encoder...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/julesberman/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auto_encoder_train_score:  0.02411004235408671\n",
      "encoding...\n",
      "encoded as:  (16281, 400)\n",
      "fit time:  0:06:35.309682\n",
      "model train score:  1.0\n",
      "Done!\n",
      "concat_then_auto_encode dim 400 train score:  1.0\n",
      "concat_then_auto_encode dim 400 valid score:  0.3678474114441417\n",
      "concat_then_auto_encode dim 400 test_fold_holdout score:  0.24373259052924792\n",
      "concat_then_auto_encode dim 400 test_superfamily_holdout score:  0.4464856230031949\n",
      "concat_then_auto_encode dim 400 test_family_holdout score:  0.9316037735849056\n",
      "layers [1200, 825, 450, 825, 1200]\n",
      "fitting auto_encoder...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/julesberman/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auto_encoder_train_score:  -0.09810211038650651\n",
      "encoding...\n",
      "encoded as:  (16281, 450)\n",
      "fit time:  0:07:33.287856\n",
      "model train score:  1.0\n",
      "Done!\n",
      "concat_then_auto_encode dim 450 train score:  1.0\n",
      "concat_then_auto_encode dim 450 valid score:  0.3651226158038147\n",
      "concat_then_auto_encode dim 450 test_fold_holdout score:  0.23119777158774374\n",
      "concat_then_auto_encode dim 450 test_superfamily_holdout score:  0.4472843450479233\n",
      "concat_then_auto_encode dim 450 test_family_holdout score:  0.9284591194968553\n",
      "layers [1200, 850, 500, 850, 1200]\n",
      "fitting auto_encoder...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/julesberman/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auto_encoder_train_score:  -0.06179153493944744\n",
      "encoding...\n",
      "encoded as:  (16281, 500)\n",
      "fit time:  0:07:43.253034\n",
      "model train score:  1.0\n",
      "Done!\n",
      "concat_then_auto_encode dim 500 train score:  1.0\n",
      "concat_then_auto_encode dim 500 valid score:  0.38283378746594005\n",
      "concat_then_auto_encode dim 500 test_fold_holdout score:  0.24930362116991645\n",
      "concat_then_auto_encode dim 500 test_superfamily_holdout score:  0.4353035143769968\n",
      "concat_then_auto_encode dim 500 test_family_holdout score:  0.9292452830188679\n",
      "layers [1200, 875, 550, 875, 1200]\n",
      "fitting auto_encoder...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/julesberman/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auto_encoder_train_score:  -0.024512166970674015\n",
      "encoding...\n",
      "encoded as:  (16281, 550)\n",
      "fit time:  0:08:54.115537\n",
      "model train score:  1.0\n",
      "Done!\n",
      "concat_then_auto_encode dim 550 train score:  1.0\n",
      "concat_then_auto_encode dim 550 valid score:  0.3896457765667575\n",
      "concat_then_auto_encode dim 550 test_fold_holdout score:  0.2562674094707521\n",
      "concat_then_auto_encode dim 550 test_superfamily_holdout score:  0.43849840255591055\n",
      "concat_then_auto_encode dim 550 test_family_holdout score:  0.9355345911949685\n",
      "layers [1200, 900, 600, 900, 1200]\n",
      "fitting auto_encoder...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/julesberman/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auto_encoder_train_score:  -0.1770244400487152\n",
      "encoding...\n",
      "encoded as:  (16281, 600)\n",
      "fit time:  0:09:42.607633\n",
      "model train score:  1.0\n",
      "Done!\n",
      "concat_then_auto_encode dim 600 train score:  1.0\n",
      "concat_then_auto_encode dim 600 valid score:  0.3923705722070845\n",
      "concat_then_auto_encode dim 600 test_fold_holdout score:  0.24512534818941503\n",
      "concat_then_auto_encode dim 600 test_superfamily_holdout score:  0.44568690095846647\n",
      "concat_then_auto_encode dim 600 test_family_holdout score:  0.9363207547169812\n",
      "layers [1200, 925, 650, 925, 1200]\n",
      "fitting auto_encoder...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/julesberman/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auto_encoder_train_score:  -0.3892306316814977\n",
      "encoding...\n",
      "encoded as:  (16281, 650)\n",
      "fit time:  0:10:16.235997\n",
      "model train score:  1.0\n",
      "Done!\n",
      "concat_then_auto_encode dim 650 train score:  1.0\n",
      "concat_then_auto_encode dim 650 valid score:  0.38419618528610355\n",
      "concat_then_auto_encode dim 650 test_fold_holdout score:  0.2562674094707521\n",
      "concat_then_auto_encode dim 650 test_superfamily_holdout score:  0.4520766773162939\n",
      "concat_then_auto_encode dim 650 test_family_holdout score:  0.9339622641509434\n",
      "layers [1200, 950, 700, 950, 1200]\n",
      "fitting auto_encoder...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/julesberman/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auto_encoder_train_score:  -0.14419528035556914\n",
      "encoding...\n",
      "encoded as:  (16281, 700)\n",
      "fit time:  0:09:48.001611\n",
      "model train score:  1.0\n",
      "Done!\n",
      "concat_then_auto_encode dim 700 train score:  1.0\n",
      "concat_then_auto_encode dim 700 valid score:  0.3814713896457766\n",
      "concat_then_auto_encode dim 700 test_fold_holdout score:  0.2479108635097493\n",
      "concat_then_auto_encode dim 700 test_superfamily_holdout score:  0.4496805111821086\n",
      "concat_then_auto_encode dim 700 test_family_holdout score:  0.9378930817610063\n"
     ]
    }
   ],
   "source": [
    "dims = []\n",
    "for d in [10, 20, 50, 100, 150, 200, 250, 300, 350, 400, 450, 500, 550, 600, 650, 700]:\n",
    "    dims.append(d)\n",
    "all_dim_all_scores = {}\n",
    "\n",
    "for d in dims:\n",
    "    s = do_conact_then_auto_encode_for_dim(X, ys, d)\n",
    "    all_dim_all_scores[str(d)] = s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"concat_then_auto_encode_across_dims_weighted_631.p\", \"wb\") as f:\n",
    "    pickle.dump(all_dim_all_scores, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
