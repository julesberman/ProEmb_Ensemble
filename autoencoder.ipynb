{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "\n",
    "import torch as T\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_dataset(model: str, task: str, split: str,  basepath='/scratch/fl1092/ml_protein_data'):\n",
    "    path_to_file = f'{basepath}/{model}/{task}/{task}_{split}.p'\n",
    "    data = np.load(path_to_file, allow_pickle=True)\n",
    "    \n",
    "    return data\n",
    "\n",
    "def dict_2_arr(data_dict, labels, avgr=lambda x: np.mean(x, axis=0)):\n",
    "    \n",
    "    emb_shape = list(data_dict.values())[0].shape\n",
    "    number_of_embeddings = len(data_dict) \n",
    "\n",
    "    X = np.zeros((number_of_embeddings, emb_shape[-1]))\n",
    "    y = np.zeros(number_of_embeddings)\n",
    "    \n",
    "    i = 0\n",
    "\n",
    "    # iter over sorted keys in labels to ensure proteins\n",
    "    # from different models are indexed the same\n",
    "    keys = list(labels.keys())\n",
    "    keys.sort()\n",
    "    for key in keys :\n",
    "        if key == 'd1smyc_':\n",
    "            continue\n",
    "        X[i] = avgr(data_dict[key])\n",
    "        y[i] = labels[key]\n",
    "        i += 1\n",
    "        \n",
    "    return X, y\n",
    "\n",
    "def ensemble_append_mean_reps(dicts, labels):\n",
    "    \n",
    "    new_dict = dict()\n",
    "    keys = dicts[0].keys()\n",
    "    for key in keys:\n",
    "        seqs = []\n",
    "        for d in dicts:\n",
    "            seq = np.mean(d[key], axis=0)\n",
    "            seq = preprocessing.normalize([seq], norm='l2')\n",
    "            seqs.append(seq)\n",
    "        combined_seqs = np.concatenate(seqs, axis=1)\n",
    "        new_dict[key] = combined_seqs\n",
    "\n",
    "    emb_size = list(new_dict.values())[0].shape[1]\n",
    "    X = np.zeros((len(new_dict), emb_size))\n",
    "    y = np.zeros(len(new_dict))\n",
    "    \n",
    "    i = 0\n",
    "    for key in new_dict:\n",
    "        X[i] = new_dict[key]\n",
    "        y[i] = labels[key]\n",
    "        i += 1\n",
    "        \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataSet(T.utils.data.Dataset):\n",
    "    # creat a Map-style dataset\n",
    "    \n",
    "    def __init__(self, task, split, device):\n",
    "        self.elmo_train = read_dataset('elmo', task, split)\n",
    "        self.unirep_train = read_dataset('unirep', task, split)\n",
    "        self.y_data = read_dataset('label', task, split)\n",
    "        \n",
    "        X_app, self.y_data = ensemble_append_mean_reps([self.elmo_train, self.unirep_train], self.y_data)\n",
    "        self.x_data = T.tensor(X_app, dtype=T.float32).to(device)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.x_data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if T.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        \n",
    "        x = self.x_data[idx, ]\n",
    "        y = self.y_data[idx]\n",
    "        \n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoder and decoder with two convolutional layers\n",
    "\n",
    "class ConvEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Encoder, self).__init__()\n",
    "        c = capacity\n",
    "        self.conv1 = nn.Conv1d(in_channels=1, out_channels=c, kernel_size=4, stride=2, padding=1) # out: c x 14 x 14\n",
    "        self.conv2 = nn.Conv1d(in_channels=c, out_channels=c*2, kernel_size=4, stride=2, padding=1) # out: c x 7 x 7\n",
    "        self.fc = nn.Linear(in_features=c*2*7*7, out_features=latent_dims)\n",
    "            \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = x.view(x.size(0), -1) # flatten batch of multi-channel feature maps to a batch of feature vectors\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "class ConvDecoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Decoder, self).__init__()\n",
    "        c = capacity\n",
    "        self.fc = nn.Linear(in_features=latent_dims, out_features=c*2*7*7)\n",
    "        self.conv2 = nn.ConvTranspose1d(in_channels=c*2, out_channels=c, kernel_size=4, stride=2, padding=1)\n",
    "        self.conv1 = nn.ConvTranspose1d(in_channels=c, out_channels=1, kernel_size=4, stride=2, padding=1)\n",
    "            \n",
    "    def forward(self, x):\n",
    "        x = self.fc(x)\n",
    "        x = x.view(x.size(0), capacity*2, 7, 7) # unflatten batch of feature vectors to a batch of multi-channel feature maps\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = torch.tanh(self.conv1(x)) # last layer before output is tanh, since the images are normalized and 0-centered\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoder and decoder with fully connected layers only\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_shape):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.fc1 = nn.Linear(in_features=input_shape, out_features=1024)\n",
    "        self.fc2 = nn.Linear(in_features=1024, out_features=128)\n",
    "        self.fc3 = nn.Linear(in_features=128, out_features=128)\n",
    "            \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, input_shape):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.fc1 = nn.Linear(in_features=128, out_features=128)\n",
    "        self.fc2 = nn.Linear(in_features=128, out_features=1024)\n",
    "        self.fc3 = nn.Linear(in_features=1024, out_features=input_shape)\n",
    "            \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self, input_shape):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.encoder = Encoder(input_shape)\n",
    "        self.decoder = Decoder(input_shape)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        latent = self.encoder(x)\n",
    "        x_recon = self.decoder(latent)\n",
    "        return x_recon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dims = 10\n",
    "num_epochs = 20\n",
    "batch_size = 128\n",
    "capacity = 64\n",
    "learning_rate = 1e-3\n",
    "use_gpu = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = T.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 16.2 s, sys: 14.4 s, total: 30.6 s\n",
      "Wall time: 30.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_data = DataSet('remote_homology', 'train', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_data, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## example data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = torchvision.transforms.Compose([torchvision.transforms.ToTensor()])\n",
    "\n",
    "train_dataset = torchvision.datasets.MNIST(\n",
    "    root=\"~/torch_datasets\", train=True, transform=transform, download=True\n",
    ")\n",
    "\n",
    "test_dataset = torchvision.datasets.MNIST(\n",
    "    root=\"~/torch_datasets\", train=False, transform=transform, download=True\n",
    ")\n",
    "\n",
    "train_loader = T.utils.data.DataLoader(\n",
    "    train_dataset, batch_size=128, shuffle=True, num_workers=4, pin_memory=True\n",
    ")\n",
    "\n",
    "test_loader = T.utils.data.DataLoader(\n",
    "    test_dataset, batch_size=32, shuffle=False, num_workers=4\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# auto-encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fully connected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 40\n",
    "learning_rate = 1e-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Autoencoder(2924).to(device)\n",
    "\n",
    "# create an optimizer object\n",
    "# Adam optimizer with learning rate 1e-3\n",
    "optimizer = T.optim.Adam(params=model.parameters(), lr=learning_rate, weight_decay=1e-7)\n",
    "\n",
    "# mean-squared error loss\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1/40, loss = 0.000789\n",
      "epoch : 4/40, loss = 0.000238\n",
      "epoch : 7/40, loss = 0.000223\n",
      "epoch : 10/40, loss = 0.000217\n",
      "epoch : 13/40, loss = 0.000215\n",
      "epoch : 16/40, loss = 0.000212\n",
      "epoch : 19/40, loss = 0.000211\n",
      "epoch : 22/40, loss = 0.000210\n",
      "epoch : 25/40, loss = 0.000209\n",
      "epoch : 28/40, loss = 0.000210\n",
      "epoch : 31/40, loss = 0.000209\n",
      "epoch : 34/40, loss = 0.000209\n",
      "epoch : 37/40, loss = 0.000210\n",
      "epoch : 40/40, loss = 0.000209\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    loss = 0\n",
    "    for batch_features, _ in train_dataloader:\n",
    "        # reshape mini-batch data to [N, 784] matrix\n",
    "        # load it to the active device\n",
    "        batch_features = batch_features.to(device)\n",
    "        \n",
    "        # reset the gradients back to zero\n",
    "        # PyTorch accumulates gradients on subsequent backward passes\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # compute reconstructions\n",
    "        outputs = model(batch_features)\n",
    "        \n",
    "        # compute training reconstruction loss\n",
    "        train_loss = criterion(outputs, batch_features)\n",
    "        \n",
    "        # compute accumulated gradients\n",
    "        train_loss.backward()\n",
    "        \n",
    "        # perform parameter update based on current gradients\n",
    "        optimizer.step()\n",
    "        \n",
    "        # add the mini-batch training loss to epoch loss\n",
    "        loss += train_loss.item()\n",
    "    \n",
    "    # compute the epoch training loss\n",
    "    loss = loss / len(train_dataloader)\n",
    "    \n",
    "    # display the epoch training loss\n",
    "    if epoch %3 == 0:\n",
    "        print(\"epoch : {}/{}, loss = {:.6f}\".format(epoch + 1, num_epochs, loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## encode to latent space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 739 ms, sys: 703 ms, total: 1.44 s\n",
      "Wall time: 1.45 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "test_data = DataSet('remote_homology', 'test', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12305, 718)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data), len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10954429adbc4af1aea29779bdb2b991",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=12305), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_x_latent = []\n",
    "train_y = []\n",
    "\n",
    "for i in tqdm(range(len(train_data))):\n",
    "    x, y = train_data[i]\n",
    "    train_x_latent.append(model.encoder(x).cpu().detach().numpy())\n",
    "    train_y.append(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6aeb2755aa58422b917512f248d8f3b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=718), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_x_latent = []\n",
    "test_y = []\n",
    "\n",
    "for i in tqdm(range(len(test_data))):\n",
    "    x, y = test_data[i]\n",
    "    test_x_latent.append(model.encoder(x).cpu().detach().numpy())\n",
    "    test_y.append(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.multiclass import OneVsRestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneVsRestClassifier(estimator=LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0),\n",
       "          n_jobs=None)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = OneVsRestClassifier(LinearSVC())\n",
    "clf.fit(train_x_latent, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0905292479108635"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(test_x_latent, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
