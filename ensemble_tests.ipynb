{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "from read_scripts import dict_2_arr \n",
    "from read_scripts import read_dataset \n",
    "# takes an array of dict_data\n",
    "# and combines embeddings by averaging with self then appending with other\n",
    "# convers to array with labels and returns\n",
    "def ensemble_append_mean_reps(dicts, labels):\n",
    "    \n",
    "    new_dict = dict()\n",
    "    keys = dicts[0].keys()\n",
    "    for key in keys:\n",
    "        seqs = []\n",
    "        for d in dicts:\n",
    "            seq = np.mean(d[key], axis=0)\n",
    "            seq = preprocessing.normalize([seq], norm='l2')\n",
    "            seqs.append(seq)\n",
    "        combined_seqs = np.concatenate(seqs, axis=1)\n",
    "        new_dict[key] = combined_seqs\n",
    "\n",
    "    emb_size = list(new_dict.values())[0].shape[1]\n",
    "    X = np.zeros((len(new_dict), emb_size))\n",
    "    y = np.zeros(len(new_dict))\n",
    "    \n",
    "    i = 0\n",
    "    for key in new_dict:\n",
    "        X[i] = new_dict[key]\n",
    "        y[i] = labels[key]\n",
    "        i += 1\n",
    "        \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = \"remote_homology\"\n",
    "\n",
    "y_train = read_dataset('label', task, \"train\")\n",
    "X_train_e = read_dataset('elmo', task, \"train\")\n",
    "X_train_u = read_dataset('unirep', task, \"train\")\n",
    "X_train_t = read_dataset('transformer', task, \"train\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12305, 3692)\n",
      "(12305,)\n"
     ]
    }
   ],
   "source": [
    "X_train_app, y_train = ensemble_append_mean_reps([X_train_e, X_train_u, X_train_t], y_train)\n",
    "scaler = preprocessing.StandardScaler().fit(X_train_app)\n",
    "X_train_app = scaler.transform(X_train_app)\n",
    "\n",
    "print(X_train_app.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit time:  0:43:56.453212\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from timeit import default_timer as timer\n",
    "from datetime import timedelta\n",
    "\n",
    "start = timer()\n",
    "clf = LogisticRegression(max_iter=5000)\n",
    "clf.fit(X_train_app, y_train)\n",
    "end = timer()\n",
    "print(f\"fit time: \", timedelta(seconds=end-start))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# when run will play a ping sound!\n",
    "os.system(\"printf '\\a'\")\n",
    "os.system(\"printf '\\a'\")\n",
    "os.system(\"printf '\\a'\")\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "append model train score:  1.0\n"
     ]
    }
   ],
   "source": [
    "train_score = clf.score(X_train_app, y_train)\n",
    "print(f\"append model train score: \", train_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "append model valid score:  0.3746594005449591\n",
      "append model test_fold_holdout score:  0.2743732590529248\n",
      "append model test_superfamily_holdout score:  0.46485623003194887\n",
      "append model test_family_holdout score:  0.9544025157232704\n"
     ]
    }
   ],
   "source": [
    "for split in ['valid', 'test_fold_holdout', 'test_superfamily_holdout', 'test_family_holdout']:\n",
    "    X_test_e = read_dataset('elmo', task, split)\n",
    "    X_test_u = read_dataset('unirep', task, split)\n",
    "    X_test_t = read_dataset('transformer', task, split)\n",
    "    y_test_dict = read_dataset('label', task, split)\n",
    "    X_test_app, y_test = ensemble_append_mean_reps([X_test_e, X_test_u, X_test_t], y_test_dict)\n",
    "    \n",
    "    X_test_app = scaler.transform(X_test_app)\n",
    "    test_score = clf.score(X_test_app, y_test)\n",
    "    print(f\"append model {split} score: \", test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils.extmath import randomized_svd\n",
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "\n",
    "# work in progress\n",
    "def ensemble_append_SVD_mean_reps(uni_dict, elmo_dict, labels, d=100):\n",
    "    \n",
    "    new_dict = dict()\n",
    "    for key in labels:\n",
    "        seqs = []\n",
    "        \n",
    "        # first normalize the samples\n",
    "        uni_sample =  preprocessing.normalize(uni_dict[key], norm='l2')\n",
    "        elmo_sample = preprocessing.normalize(elmo_dict[key], norm='l2')\n",
    "        \n",
    "        # get full SVD if the length is less than the dimensionality reduction, d\n",
    "        need_full = False\n",
    "        if uni_sample.shape[0] < d:\n",
    "            need_full = True\n",
    "        \n",
    "        # extend elmo sample by two to match unirep\n",
    "        elmo_sample = np.append([elmo_sample[0]], [*elmo_sample, elmo_sample[-1]], axis=0)\n",
    "\n",
    "        # concatenate samples\n",
    "        combined_embd = np.concatenate([uni_sample, elmo_sample], axis=1)\n",
    "\n",
    "        print(combined_embd.shape)\n",
    "        \n",
    "        # compute svd\n",
    "        U, S, _ = np.linalg.svd(combined_embd, full_matrices=need_full)\n",
    "           \n",
    "        print(U.shape)      \n",
    "        print(U[:d].shape)   \n",
    "        \n",
    "        # take mean for single vector\n",
    "        final_emb = np.mean(U[:d], axis=1)\n",
    "        \n",
    "        print(final_emb.shape) \n",
    "            \n",
    "        # set into dict\n",
    "        new_dict[key] = final_emb\n",
    "\n",
    "    # dict to array\n",
    "    emb_size = list(new_dict.values())[0].shape[0]\n",
    "    X = np.zeros((len(new_dict), emb_size))\n",
    "    y = np.zeros(len(new_dict))\n",
    "    \n",
    "    i = 0\n",
    "    for key in new_dict:\n",
    "        X[i] = new_dict[key]\n",
    "        y[i] = labels[key]\n",
    "        i += 1\n",
    "        \n",
    "    return X, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reducing to dim 734\n",
      "(734, 734)\n",
      "(734, 734)\n"
     ]
    }
   ],
   "source": [
    "from scipy.linalg import orthogonal_procrustes\n",
    "from sklearn.decomposition import PCA\n",
    "# work in progress\n",
    "def ensemble_PCA_orthogonal_procrustes_reps(m1, m2, min_dim=99999999):\n",
    "    \n",
    "    min_dim = min(min(min_dim, m1.shape[0]), m2.shape[0])\n",
    "    print(\"reducing to dim\", min_dim)\n",
    "    \n",
    "    if m1.shape[1] > min_dim:\n",
    "        m1 = PCA(n_components=min_dim).fit(m1).transform(m1)\n",
    "        print(m1.shape)\n",
    "        \n",
    "    if m2.shape[1] > min_dim:\n",
    "        m2 = PCA(n_components=min_dim).fit(m2).transform(m2)\n",
    "        print(m2.shape)\n",
    "\n",
    "ensemble_PCA_orthogonal_procrustes_reps(X_e, X_u)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
